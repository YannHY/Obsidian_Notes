---
tags: [documentation, intelligence artificielle]
author: [Yann Houry]
date: 23-10-2022
---

[Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206) (AIA)

## Europe Is in Danger of Using the Wrong Definition of AI
[Lien](https://www.wired.com/story/artificial-intelligence-regulation-european-union/)

Article très intéressant proposant une définition de l'IA qui permette au régulateur européen de proposer les lois les plus justes (une définition trop restrictive permettrait à certains acteurs d'échapper aux régulations ou au contraire de bénéficier de certains avantages)

### Définition de l'IA
> The current draft of the AIA starts with a very broad definition of AI: “==software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with.==” This may already be too narrow a definition of AI, given what the AIA is primarily about—ensuring that decisions taken by or with machines are done so well, transparently, and with clear human accountability, at least if those decisions matter.

«système d’intelligence artificielle» (système d’IA), un logiciel qui est développé au moyen d’une ou plusieurs des techniques et approches énumérées à l’annexe I et qui peut, pour un ensemble donné d’objectifs définis par l’homme, générer des résultats tels que des contenus, des prédictions, des recommandations ou des décisions influençant les environnements avec lesquels il interagit;

Voir plus bas :

> Definitions aside, the rest of the AIA makes clear that what legislators care about with respect to AI are its outcomes. The details of how artifacts perform these tasks are only important to the extent that they determine how hard it is to provide transparency and maintain accountability. ==In this context, “the computing of appropriate action from context” is the best definition of AI for the AIA== because it doesn’t get bogged down in technical details but instead allows the focus to remain on consequences.

### Définition de l'intelligence
> For the purposes of digital governance instruments like the AIA, it makes more sense to use a well-established definition of intelligence, dating back to scientists’ first explorations of the evolutionary origins of the human trait by looking at other species: ==the capacity to act effectively in response to changing contexts==. Rocks aren’t intelligent at all, plants are a little intelligent, bees more so, monkeys more so again. Intelligence by this definition is evidently a computational process: the conversion of information about the world into some action. ==This definition is generally useful because it reminds (or explains to) people that intelligence is not some supernatural property, or just “human-likeness,” but rather a physical process we find throughout nature to varying degrees==. It reminds us that AI requires physical as well as legal infrastructure. ==AI needs computers and communications at least as much as it needs data and algorithms. AI requires power and materials and produces pollution and waste==.

Dangers de l'automatisation :

> The challenge is that a single mistake made in development may be repeated millions of times by automation without further thought. This is what happened with the British Post Office system. Twenty years ago, [Fujitsu wrote new software for the British Post Office; immediately, bugs were reported](https://en.wikipedia.org/wiki/British_Post_Office_scandal). But those reports were ignored, not least because [the British had passed a law saying that software is reliable](https://journals.sas.ac.uk/deeslr/article/view/5395). Therefore, the software accounts were believed and the post office workers were not. Even if they had years of good service, post office workers were forced to privately make up enormous “financial discrepancies.” Lives were ruined, families were bankrupted, people were jailed, deaths, including suicides, occurred. Twenty years later [the case of these workers is only now being heard](https://www.theguardian.com/commentisfree/2022/feb/15/post-office-scandal-workers-computer-system). This is why we need good oversight for any “high risk” digital system—the systems that change lives.